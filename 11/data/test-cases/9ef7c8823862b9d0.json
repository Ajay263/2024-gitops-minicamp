{"uid":"9ef7c8823862b9d0","name":"test_load_order_fulfillment_data","fullName":"test_order_fulfillment#test_load_order_fulfillment_data","historyId":"5797e8a1a81fd60bd28b0832aeb93839","time":{"start":1741761821806,"stop":1741761821876,"duration":70},"description":"Test that data can be loaded from S3 with the correct schema.","descriptionHtml":"<p>Test that data can be loaded from S3 with the correct schema.</p>\n","status":"broken","statusMessage":"py4j.protocol.Py4JJavaError: An error occurred while calling o126.load.\n: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"s3\"\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)\n\tat org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)","statusTrace":"mock_boto3_client = <MagicMock name='client' id='139716046438304'>\nglue_context = <MagicMock id='139716058802352'>, s3_bucket = 'test-bucket'\n\n    @patch(\"boto3.client\")\n    def test_load_order_fulfillment_data(mock_boto3_client, glue_context, s3_bucket):\n        \"\"\"Test that data can be loaded from S3 with the correct schema.\"\"\"\n        # Setup\n        s3_path = f\"s3://{s3_bucket}/input/order_fulfillment.csv\"\n        sample_csv = \"\"\"ORDER_ID,on.time,in_full,OTIF\n    FMR32103503,1.0,0.0,0.0\n    FMR34103403,1.0,-1.0,0.0\n    FMR32103602,1.0 units,0.0,0.0\n    FMR33103602,1.0,0.0,0.0\"\"\"\n    \n        # Create a mock DataFrame that the function should return\n        pandas_df = pd.DataFrame(\n            {\n                \"ORDER_ID\": [\"FMR32103503\", \"FMR34103403\", \"FMR32103602\", \"FMR33103602\"],\n                \"on.time\": [1.0, 1.0, \"1.0 units\", 1.0],\n                \"in_full\": [0.0, -1.0, 0.0, 0.0],\n                \"OTIF\": [0.0, 0.0, 0.0, 0.0],\n            }\n        )\n        expected_df = glue_context.spark_session.createDataFrame(pandas_df)\n    \n        # Mock S3 client to return our sample data\n        s3_client = boto3.client(\"s3\", region_name=\"us-east-1\")\n        s3_client.put_object(\n            Bucket=s3_bucket, Key=\"input/order_fulfillment.csv\", Body=sample_csv\n        )\n    \n        # Mock the read functionality to return our expected DataFrame\n        with patch.object(glue_context.spark_session.read, \"format\") as mock_format:\n            mock_chain = mock_format.return_value\n            mock_chain.option.return_value.schema.return_value.load.return_value = (\n                expected_df\n            )\n    \n            # Execute\n>           result_df = load_order_fulfillment_data(glue_context, s3_path)\n\ntest_order_fulfillment.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../scripts/order_fulfillment.py:38: in load_order_fulfillment_data\n    glue_context.spark_session.read.format(\"csv\")\n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/pyspark/sql/readwriter.py:307: in load\n    return self._df(self._jreader.load(path))\n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/py4j/java_gateway.py:1322: in __call__\n    return_value = get_return_value(\n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/pyspark/errors/exceptions/captured.py:179: in deco\n    return f(*a, **kw)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nanswer = 'xro127'\ngateway_client = <py4j.clientserver.JavaClient object at 0x7f122e0dec10>\ntarget_id = 'o126', name = 'load'\n\n    def get_return_value(answer, gateway_client, target_id=None, name=None):\n        \"\"\"Converts an answer received from the Java gateway into a Python object.\n    \n        For example, string representation of integers are converted to Python\n        integer, string representation of objects are converted to JavaObject\n        instances, etc.\n    \n        :param answer: the string returned by the Java gateway\n        :param gateway_client: the gateway client used to communicate with the Java\n            Gateway. Only necessary if the answer is a reference (e.g., object,\n            list, map)\n        :param target_id: the name of the object from which the answer comes from\n            (e.g., *object1* in `object1.hello()`). Optional.\n        :param name: the name of the member from which the answer comes from\n            (e.g., *hello* in `object1.hello()`). Optional.\n        \"\"\"\n        if is_error(answer)[0]:\n            if len(answer) > 1:\n                type = answer[1]\n                value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)\n                if answer[1] == REFERENCE_TYPE:\n>                   raise Py4JJavaError(\n                        \"An error occurred while calling {0}{1}{2}.\\n\".\n                        format(target_id, \".\", name), value)\nE                   py4j.protocol.Py4JJavaError: An error occurred while calling o126.load.\nE                   : org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"s3\"\nE                   \tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\nE                   \tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\nE                   \tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\nE                   \tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\nE                   \tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\nE                   \tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\nE                   \tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\nE                   \tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)\nE                   \tat scala.collection.immutable.List.map(List.scala:293)\nE                   \tat org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)\nE                   \tat org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)\nE                   \tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)\nE                   \tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\nE                   \tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\nE                   \tat scala.Option.getOrElse(Option.scala:189)\nE                   \tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\nE                   \tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\nE                   \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nE                   \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\nE                   \tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nE                   \tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\nE                   \tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\nE                   \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\nE                   \tat py4j.Gateway.invoke(Gateway.java:282)\nE                   \tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\nE                   \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\nE                   \tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\nE                   \tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\nE                   \tat java.base/java.lang.Thread.run(Thread.java:840)\n\n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/py4j/protocol.py:326: Py4JJavaError","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[{"name":"spark","time":{"start":1741761816980,"stop":1741761819509,"duration":2529},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"glue_context","time":{"start":1741761819510,"stop":1741761819510,"duration":0},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"s3_bucket","time":{"start":1741761821644,"stop":1741761821805,"duration":161},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false}],"testStage":{"description":"Test that data can be loaded from S3 with the correct schema.","status":"broken","statusMessage":"py4j.protocol.Py4JJavaError: An error occurred while calling o126.load.\n: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"s3\"\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)\n\tat org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)","statusTrace":"mock_boto3_client = <MagicMock name='client' id='139716046438304'>\nglue_context = <MagicMock id='139716058802352'>, s3_bucket = 'test-bucket'\n\n    @patch(\"boto3.client\")\n    def test_load_order_fulfillment_data(mock_boto3_client, glue_context, s3_bucket):\n        \"\"\"Test that data can be loaded from S3 with the correct schema.\"\"\"\n        # Setup\n        s3_path = f\"s3://{s3_bucket}/input/order_fulfillment.csv\"\n        sample_csv = \"\"\"ORDER_ID,on.time,in_full,OTIF\n    FMR32103503,1.0,0.0,0.0\n    FMR34103403,1.0,-1.0,0.0\n    FMR32103602,1.0 units,0.0,0.0\n    FMR33103602,1.0,0.0,0.0\"\"\"\n    \n        # Create a mock DataFrame that the function should return\n        pandas_df = pd.DataFrame(\n            {\n                \"ORDER_ID\": [\"FMR32103503\", \"FMR34103403\", \"FMR32103602\", \"FMR33103602\"],\n                \"on.time\": [1.0, 1.0, \"1.0 units\", 1.0],\n                \"in_full\": [0.0, -1.0, 0.0, 0.0],\n                \"OTIF\": [0.0, 0.0, 0.0, 0.0],\n            }\n        )\n        expected_df = glue_context.spark_session.createDataFrame(pandas_df)\n    \n        # Mock S3 client to return our sample data\n        s3_client = boto3.client(\"s3\", region_name=\"us-east-1\")\n        s3_client.put_object(\n            Bucket=s3_bucket, Key=\"input/order_fulfillment.csv\", Body=sample_csv\n        )\n    \n        # Mock the read functionality to return our expected DataFrame\n        with patch.object(glue_context.spark_session.read, \"format\") as mock_format:\n            mock_chain = mock_format.return_value\n            mock_chain.option.return_value.schema.return_value.load.return_value = (\n                expected_df\n            )\n    \n            # Execute\n>           result_df = load_order_fulfillment_data(glue_context, s3_path)\n\ntest_order_fulfillment.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../scripts/order_fulfillment.py:38: in load_order_fulfillment_data\n    glue_context.spark_session.read.format(\"csv\")\n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/pyspark/sql/readwriter.py:307: in load\n    return self._df(self._jreader.load(path))\n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/py4j/java_gateway.py:1322: in __call__\n    return_value = get_return_value(\n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/pyspark/errors/exceptions/captured.py:179: in deco\n    return f(*a, **kw)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nanswer = 'xro127'\ngateway_client = <py4j.clientserver.JavaClient object at 0x7f122e0dec10>\ntarget_id = 'o126', name = 'load'\n\n    def get_return_value(answer, gateway_client, target_id=None, name=None):\n        \"\"\"Converts an answer received from the Java gateway into a Python object.\n    \n        For example, string representation of integers are converted to Python\n        integer, string representation of objects are converted to JavaObject\n        instances, etc.\n    \n        :param answer: the string returned by the Java gateway\n        :param gateway_client: the gateway client used to communicate with the Java\n            Gateway. Only necessary if the answer is a reference (e.g., object,\n            list, map)\n        :param target_id: the name of the object from which the answer comes from\n            (e.g., *object1* in `object1.hello()`). Optional.\n        :param name: the name of the member from which the answer comes from\n            (e.g., *hello* in `object1.hello()`). Optional.\n        \"\"\"\n        if is_error(answer)[0]:\n            if len(answer) > 1:\n                type = answer[1]\n                value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)\n                if answer[1] == REFERENCE_TYPE:\n>                   raise Py4JJavaError(\n                        \"An error occurred while calling {0}{1}{2}.\\n\".\n                        format(target_id, \".\", name), value)\nE                   py4j.protocol.Py4JJavaError: An error occurred while calling o126.load.\nE                   : org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"s3\"\nE                   \tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\nE                   \tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\nE                   \tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\nE                   \tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\nE                   \tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\nE                   \tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\nE                   \tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\nE                   \tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)\nE                   \tat scala.collection.immutable.List.map(List.scala:293)\nE                   \tat org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)\nE                   \tat org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)\nE                   \tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)\nE                   \tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\nE                   \tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\nE                   \tat scala.Option.getOrElse(Option.scala:189)\nE                   \tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\nE                   \tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\nE                   \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nE                   \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\nE                   \tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nE                   \tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\nE                   \tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\nE                   \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\nE                   \tat py4j.Gateway.invoke(Gateway.java:282)\nE                   \tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\nE                   \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\nE                   \tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\nE                   \tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\nE                   \tat java.base/java.lang.Thread.run(Thread.java:840)\n\n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/py4j/protocol.py:326: Py4JJavaError","steps":[],"attachments":[{"uid":"b6f007d8201ed6dc","name":"stderr","source":"b6f007d8201ed6dc.txt","type":"text/plain","size":6741}],"parameters":[],"shouldDisplayMessage":true,"stepsCount":0,"attachmentsCount":1,"hasContent":true,"attachmentStep":false},"afterStages":[{"name":"s3_bucket::0","time":{"start":1741761821966,"stop":1741761821967,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false}],"labels":[{"name":"suite","value":"test_order_fulfillment"},{"name":"host","value":"fv-az791-129"},{"name":"thread","value":"2992-MainThread"},{"name":"framework","value":"pytest"},{"name":"language","value":"cpython3"},{"name":"package","value":"test_order_fulfillment"},{"name":"resultFormat","value":"allure2"}],"parameters":[],"links":[],"hidden":true,"retry":true,"extra":{"categories":[],"tags":[]},"source":"9ef7c8823862b9d0.json","parameterValues":[]}