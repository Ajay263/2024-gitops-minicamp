{"uid":"4b4757e66a1912dae1a509f688f20b0f","children":[{"name":"Test defects","children":[{"name":"pyspark.errors.exceptions.captured.SparkUpgradeException: [INCONSISTENT_BEHAVIOR_CROSS_VERSION.DATETIME_PATTERN_RECOGNITION] You may get a different result due to the upgrading to Spark >= 3.0:\nFail to recognize 'EEEE, MMMM d, yyyy' pattern in the DateTimeFormatter. 1) You can set \"spark.sql.legacy.timeParserPolicy\" to \"LEGACY\" to restore the behavior before Spark 3.0. 2) You can form a valid datetime pattern with the guide from 'https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html'.","children":[{"name":"test_clean_agreed_delivery_date","uid":"eff50823c3636134","parentUid":"212da4e0a10d799fc462a973bcc24575","status":"broken","time":{"start":1744626175330,"stop":1744626175485,"duration":155},"flaky":false,"newFailed":false,"newPassed":false,"newBroken":false,"retriesCount":3,"retriesStatusChange":false,"parameters":[],"tags":[]},{"name":"test_clean_actual_delivery_date","uid":"21cdd3e75e15ef8e","parentUid":"212da4e0a10d799fc462a973bcc24575","status":"broken","time":{"start":1744626176898,"stop":1744626177055,"duration":157},"flaky":false,"newFailed":false,"newPassed":false,"newBroken":false,"retriesCount":3,"retriesStatusChange":false,"parameters":[],"tags":[]},{"name":"test_clean_order_lines_data_integration","uid":"9b7f1e224aedec4e","parentUid":"212da4e0a10d799fc462a973bcc24575","status":"broken","time":{"start":1744626180275,"stop":1744626180664,"duration":389},"flaky":false,"newFailed":false,"newPassed":false,"newBroken":false,"retriesCount":3,"retriesStatusChange":false,"parameters":[],"tags":[]}],"uid":"212da4e0a10d799fc462a973bcc24575"}],"uid":"bdbf199525818fae7a8651db9eafe741"}],"name":"categories"}