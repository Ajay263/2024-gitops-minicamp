{"uid":"4b4757e66a1912dae1a509f688f20b0f","children":[{"name":"Test defects","children":[{"name":"pyspark.errors.exceptions.captured.SparkUpgradeException: [INCONSISTENT_BEHAVIOR_CROSS_VERSION.DATETIME_PATTERN_RECOGNITION] You may get a different result due to the upgrading to Spark >= 3.0:\nFail to recognize 'EEEE, MMMM d, yyyy' pattern in the DateTimeFormatter. 1) You can set \"spark.sql.legacy.timeParserPolicy\" to \"LEGACY\" to restore the behavior before Spark 3.0. 2) You can form a valid datetime pattern with the guide from 'https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html'.","children":[{"name":"test_clean_agreed_delivery_date","uid":"60b933d2cf64ffca","parentUid":"212da4e0a10d799fc462a973bcc24575","status":"broken","time":{"start":1744629552692,"stop":1744629552835,"duration":143},"flaky":false,"newFailed":false,"newPassed":false,"newBroken":false,"retriesCount":3,"retriesStatusChange":false,"parameters":[],"tags":[]},{"name":"test_clean_actual_delivery_date","uid":"c7856e01bdde32c8","parentUid":"212da4e0a10d799fc462a973bcc24575","status":"broken","time":{"start":1744629554204,"stop":1744629554352,"duration":148},"flaky":false,"newFailed":false,"newPassed":false,"newBroken":false,"retriesCount":3,"retriesStatusChange":false,"parameters":[],"tags":[]},{"name":"test_clean_order_lines_data_integration","uid":"7a8da2f6a6152a16","parentUid":"212da4e0a10d799fc462a973bcc24575","status":"broken","time":{"start":1744629557070,"stop":1744629557383,"duration":313},"flaky":false,"newFailed":false,"newPassed":false,"newBroken":false,"retriesCount":3,"retriesStatusChange":false,"parameters":[],"tags":[]}],"uid":"212da4e0a10d799fc462a973bcc24575"}],"uid":"bdbf199525818fae7a8651db9eafe741"}],"name":"categories"}