{"uid":"4b4757e66a1912dae1a509f688f20b0f","children":[{"name":"Test defects","children":[{"name":"pyspark.errors.exceptions.captured.SparkUpgradeException: [INCONSISTENT_BEHAVIOR_CROSS_VERSION.DATETIME_PATTERN_RECOGNITION] You may get a different result due to the upgrading to Spark >= 3.0:\nFail to recognize 'EEEE, MMMM d, yyyy' pattern in the DateTimeFormatter. 1) You can set \"spark.sql.legacy.timeParserPolicy\" to \"LEGACY\" to restore the behavior before Spark 3.0. 2) You can form a valid datetime pattern with the guide from 'https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html'.","children":[{"name":"test_clean_agreed_delivery_date","uid":"822c5a72d8e33f78","parentUid":"212da4e0a10d799fc462a973bcc24575","status":"broken","time":{"start":1744633638926,"stop":1744633639074,"duration":148},"flaky":false,"newFailed":false,"newPassed":false,"newBroken":false,"retriesCount":3,"retriesStatusChange":false,"parameters":[],"tags":[]},{"name":"test_clean_actual_delivery_date","uid":"41acb2bc5399a049","parentUid":"212da4e0a10d799fc462a973bcc24575","status":"broken","time":{"start":1744633640425,"stop":1744633640569,"duration":144},"flaky":false,"newFailed":false,"newPassed":false,"newBroken":false,"retriesCount":3,"retriesStatusChange":false,"parameters":[],"tags":[]},{"name":"test_clean_order_lines_data_integration","uid":"1ce4f17657470390","parentUid":"212da4e0a10d799fc462a973bcc24575","status":"broken","time":{"start":1744633643207,"stop":1744633643534,"duration":327},"flaky":false,"newFailed":false,"newPassed":false,"newBroken":false,"retriesCount":3,"retriesStatusChange":false,"parameters":[],"tags":[]}],"uid":"212da4e0a10d799fc462a973bcc24575"}],"uid":"bdbf199525818fae7a8651db9eafe741"}],"name":"categories"}