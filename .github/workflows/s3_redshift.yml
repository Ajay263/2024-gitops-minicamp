name: S3 to Redshift ETL Job Deployment

on:
  workflow_dispatch:
  push:
    paths:
      - 'terraform/modules/scripts/**'
    branches:
      - main
      - develop

permissions:
  contents: read
  id-token: write

jobs:
  deploy-glue:
    name: 'Deploy S3 to Redshift ETL Job'
    runs-on: ubuntu-latest
    environment: production
    defaults:
      run:
        shell: bash
    
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.ROLE_TO_ASSUME }}
          aws-region: us-east-1
      
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install boto3 pytest pandas awswrangler
      
      - name: Run Tests
        run: |
          pytest terraform/modules/scripts/tests/ -v
      
      - name: Upload Glue Script to S3
        run: |
          aws s3 cp terraform/modules/scripts/s3_to_redshift.py "s3://${CODE_BUCKET}/s3_to_redshift.py"
        env:
          CODE_BUCKET: ${{ secrets.CODE_BUCKET }}
      
      - name: Deploy Glue Job
        run: |
          aws glue update-job \
            --job-name "topdevs-${ENVIRONMENT}-s3-to-redshift-job" \
            --job-update '{
              "Command": {
                "Name": "glueetl",
                "ScriptLocation": "s3://'${CODE_BUCKET}'/s3_to_redshift.py",
                "PythonVersion": "3"
              },
              "GlueVersion": "4.0",
              "WorkerType": "G.1X",
              "NumberOfWorkers": 2,
              "Timeout": 2880,
              "MaxRetries": 1,
              "DefaultArguments": {
                "--enable-auto-scaling": "true",
                "--enable-continuous-cloudwatch-log": "true",
                "--enable-metrics": "true",
                "--job-language": "python",
                "--source-bucket": "'${SOURCE_BUCKET}'",
                "--redshift-database": "'${REDSHIFT_DATABASE}'",
                "--redshift-schema": "'${REDSHIFT_SCHEMA}'",
                "--redshift-workgroup": "'${REDSHIFT_WORKGROUP}'",
                "--redshift-temp-dir": "s3://'${CODE_BUCKET}'/temp/",
                "--TempDir": "s3://'${CODE_BUCKET}'/temporary/",
                "--enable-spark-ui": "true",
                "--spark-event-logs-path": "s3://'${CODE_BUCKET}'/spark-logs/",
                "--additional-python-modules": "pandas,awswrangler"
              }
            }'
        env:
          ENVIRONMENT: ${{ secrets.ENVIRONMENT }}
          CODE_BUCKET: ${{ secrets.CODE_BUCKET }}
          SOURCE_BUCKET: ${{ secrets.SOURCE_BUCKET }}
          REDSHIFT_DATABASE: ${{ secrets.REDSHIFT_DATABASE }}
          REDSHIFT_SCHEMA: ${{ secrets.REDSHIFT_SCHEMA }}
          REDSHIFT_WORKGROUP: ${{ secrets.REDSHIFT_WORKGROUP }}
      
      - name: Verify Deployment
        run: |
          JOB_NAME="topdevs-${ENVIRONMENT}-s3-to-redshift-job"
          JOB_INFO=$(aws glue get-job --job-name "$JOB_NAME")
          echo "Verifying job configuration..."
          echo "$JOB_INFO" | jq .
          
          if [ $? -eq 0 ]; then
            echo "✅ Job deployment verified successfully"
          else
            echo "❌ Job verification failed"
            exit 1
          fi
        env:
          ENVIRONMENT: ${{ secrets.ENVIRONMENT }}