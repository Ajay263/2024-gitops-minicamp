name: DBT CI/CD Pipeline

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to run against'
        required: true
        default: 'production'
        type: choice
        options:
        - production
        - development
      full_refresh:
        description: 'Run with full refresh'
        required: false
        default: false
        type: boolean

jobs:
  dbt_ci_cd_job:
    environment: ${{ github.event.inputs.environment || 'production' }}
    runs-on: ubuntu-latest
    env:
      S3_BUCKET_PATH: ${{ secrets.CODE_BUCKET }}
    permissions:
      id-token: write 
      contents: read 
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: List repository structure
        run: |
          echo "Repository structure:"
          find . -name "dbt_project.yml" -type f
          find . -name "profiles.yml" -type f
          find . -name "packages.yml" -type f
          echo "---"
          ls -la airflow/dbt/nexabrands_dbt/ || echo "Directory not found"

      - name: Install dependencies
        run: |
          pip install -r airflow/requirements_dbt_venv.txt || echo "Requirements file not found"
          pip install dbt-redshift==1.8.1 awscli psycopg2-binary

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.ROLE_TO_ASSUME }}
          aws-region: us-east-1
          
      - name: Get Redshift Workgroup Endpoint
        id: get-endpoint
        run: |
          ENDPOINT=$(aws redshift-serverless get-workgroup --workgroup-name nexabrands-redshift-workgroup --query 'workgroup.endpoint.address' --output text)
          echo "REDSHIFT_ENDPOINT=${ENDPOINT}" >> $GITHUB_ENV
          echo "Retrieved Redshift endpoint: ${ENDPOINT}"

      - name: Find DBT project directory
        id: find-dbt
        run: |
          DBT_PROJECT_DIR=$(find . -name "dbt_project.yml" -type f | xargs dirname | head -n 1)
          if [ -z "$DBT_PROJECT_DIR" ]; then
            echo "No dbt_project.yml found. Looking for folder structure..."
            if [ -d "airflow/dbt/nexabrands_dbt" ]; then
              DBT_PROJECT_DIR="airflow/dbt/nexabrands_dbt"
            fi
          fi
          echo "DBT_PROJECT_DIR=${DBT_PROJECT_DIR}" >> $GITHUB_ENV
          echo "Using DBT project directory: ${DBT_PROJECT_DIR}"
          ls -la ${DBT_PROJECT_DIR} || echo "Directory not accessible"

      - name: Create profiles.yml
        run: |
          mkdir -p $DBT_PROJECT_DIR
          cat > $DBT_PROJECT_DIR/profiles.yml <<EOF
          nexabrands_dbt:
            outputs:
              prod:
                type: redshift
                host: ${REDSHIFT_ENDPOINT}
                user: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_USER }}
                password: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_PASSWORD }}
                port: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_PORT }}
                dbname: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_DATABASE }}
                schema: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_SCHEMA }}
                threads: 4
                keepalives_idle: 0
                connect_timeout: 120
                retries: 3
            target: prod
          EOF
          
          # Also copy to root for dbt debug
          cp $DBT_PROJECT_DIR/profiles.yml ./profiles.yml
          
          # Debug - print the profiles.yml without credentials
          cat $DBT_PROJECT_DIR/profiles.yml | sed 's/\(password: \).*/\1***/' | sed 's/\(host: \).*/\1***/'
      
      - name: Prepare S3 for dbt artifacts
        run: |
          aws s3api head-bucket --bucket ${{ secrets.CODE_BUCKET }} || aws s3 mb s3://${{ secrets.CODE_BUCKET }}
          aws s3 ls s3://${{ secrets.CODE_BUCKET }}/dbt-docs/ || aws s3api put-object --bucket ${{ secrets.CODE_BUCKET }} --key dbt-docs/
          
      - name: Download previous manifest for slim CI
        run: |
          echo "Downloading manifest from s3://${{ secrets.CODE_BUCKET }}/dbt-docs/manifest.json"
          aws s3 cp s3://${{ secrets.CODE_BUCKET }}/dbt-docs/manifest.json ./manifest.json || echo "No previous manifest found"

      - name: Run dbt debug
        working-directory: ${{ env.DBT_PROJECT_DIR }}
        env:
          DBT_PROFILES_DIR: .
        run: |
          dbt --version
          dbt debug --target prod --profiles-dir .

      - name: Run dbt deps
        working-directory: ${{ env.DBT_PROJECT_DIR }}
        env:
          DBT_PROFILES_DIR: .
        run: dbt deps --target prod --profiles-dir .

      - name: Run dbt test (PR only - Slim CI)
        if: github.event_name == 'pull_request'
        working-directory: ${{ env.DBT_PROJECT_DIR }}
        env:
          DBT_PROFILES_DIR: .
        run: |
          if [ -f "../../manifest.json" ]; then
            echo "Running slim CI tests on modified models only"
            dbt test --select state:modified+ --defer --state ../../ --target prod --profiles-dir .
          else
            echo "No previous manifest found, running all tests"
            dbt test --target prod --profiles-dir .
          fi

      - name: Run dbt build (main branch or manual dispatch)
        if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
        working-directory: ${{ env.DBT_PROJECT_DIR }}
        env:
          DBT_PROFILES_DIR: .
        run: |
          if [ "${{ github.event.inputs.full_refresh }}" == "true" ]; then
            echo "Running with full refresh"
            dbt build --full-refresh --target prod --profiles-dir .
          elif [ -f "../../manifest.json" ] && [ "${{ github.event_name }}" != "workflow_dispatch" ]; then
            echo "Running slim CI build on modified models only"
            dbt build --select state:modified+ --defer --state ../../ --target prod --profiles-dir .
          else
            echo "Running normal build"
            dbt build --target prod --profiles-dir .
          fi

      - name: Generate dbt docs
        if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
        working-directory: ${{ env.DBT_PROJECT_DIR }}
        env:
          DBT_PROFILES_DIR: .
        run: dbt docs generate --target prod --profiles-dir .

      - name: Upload manifest and docs to S3
        if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
        run: |
          aws s3 cp $DBT_PROJECT_DIR/target/manifest.json s3://${{ secrets.CODE_BUCKET }}/dbt-docs/ || echo "No manifest.json found"
          aws s3 cp $DBT_PROJECT_DIR/target/catalog.json s3://${{ secrets.CODE_BUCKET }}/dbt-docs/ || echo "No catalog.json found"
          aws s3 cp $DBT_PROJECT_DIR/target/index.html s3://${{ secrets.CODE_BUCKET }}/dbt-docs/ || echo "No index.html found"
          echo "Uploaded documentation to S3"
          
      - name: Verify uploads
        if: (github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch') && success()
        run: |
          echo "Verifying uploads..."
          aws s3 ls s3://${{ secrets.CODE_BUCKET }}/dbt-docs/ || echo "Upload verification failed!"