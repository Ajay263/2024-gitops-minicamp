name: DBT CI/CD Pipeline

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  dbt_ci_cd:
    runs-on: ubuntu-latest
    env:
      DBT_PROFILES_DIR: .
      REDSHIFT_HOST: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_HOST }}
      REDSHIFT_USER: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_USER }}
      REDSHIFT_PASSWORD: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_PASSWORD }}
      REDSHIFT_PORT: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_PORT }}
      REDSHIFT_DBNAME: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_DATABASE }}
      REDSHIFT_SCHEMA: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_SCHEMA }}
      S3_BUCKET_PATH: ${{ secrets.CODE_BUCKET }}
    permissions:
      id-token: write # Required for OIDC authentication
      contents: read # Required to checkout the repository
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Fetch all history for proper state comparison

      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install -r airflow/requirements_dbt_venv.txt
          pip install awscli psycopg2-binary

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.ROLE_TO_ASSUME }}
          aws-region: us-east-1

      - name: Create profiles.yml
        run: |
          cat > profiles.yml <<EOF
          nexabrands_dbt:
            outputs:
              prod:
                type: redshift
                host: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_HOST }}
                user: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_USER }}
                password: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_PASSWORD }}
                port: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_PORT }}
                dbname: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_DATABASE }}
                schema: ${{ secrets.DBT_ENV_SECRET_REDSHIFT_SCHEMA }}
                threads: 4
                keepalives_idle: 0
                connect_timeout: 60
            target: prod
          EOF

      - name: Verify Redshift Connection
        run: |
          python -c "
          import psycopg2
          conn = psycopg2.connect(
              host='${{ secrets.DBT_ENV_SECRET_REDSHIFT_HOST }}',
              port='${{ secrets.DBT_ENV_SECRET_REDSHIFT_PORT }}',
              dbname='${{ secrets.DBT_ENV_SECRET_REDSHIFT_DATABASE }}',
              user='${{ secrets.DBT_ENV_SECRET_REDSHIFT_USER }}',
              password='${{ secrets.DBT_ENV_SECRET_REDSHIFT_PASSWORD }}'
          )
          cur = conn.cursor()
          cur.execute('SELECT current_user, current_database()')
          print(cur.fetchone())
          conn.close()
          "

      - name: Download previous manifest
        run: |
          aws s3 cp s3://${{ secrets.CODE_BUCKET }}/dbt-docs/manifest.json ./manifest.json || echo "No previous manifest found"

      - name: Run dbt debug
        run: dbt debug --target prod

      - name: Run dbt deps
        run: dbt deps --target prod

      - name: Run dbt test (PR only)
        if: github.event_name == 'pull_request'
        run: |
          if [ -f "./manifest.json" ]; then
            dbt test -s 'state:modified+' --state ./ --target prod
          else
            dbt test --target prod
          fi

      - name: Run dbt build (main branch only)
        if: github.ref == 'refs/heads/main'
        run: |
          if [ -f "./manifest.json" ]; then
            dbt build -s 'state:modified+' --state ./ --target prod
          else
            dbt build --target prod
          fi

      - name: Copy new manifest to S3 (main branch only)
        if: github.ref == 'refs/heads/main'
        run: |
          aws s3 cp ./target/manifest.json s3://${{ secrets.CODE_BUCKET }}dbt-docs/
