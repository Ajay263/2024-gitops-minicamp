name: Deploy AWS Glue Job

on: workflow_dispatch

permissions:
  contents: read
  id-token: write

jobs:
  deploy-glue:
    name: 'Deploy Glue Job'
    runs-on: ubuntu-latest
    environment: production
    defaults:
      run:
        shell: bash

    steps:
    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ secrets.ROLE_TO_ASSUME }}
        aws-region: us-east-1
    
    - name: Checkout
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install boto3 pytest

    - name: Upload Glue Script to S3
      run: |
        aws s3 cp terraform/modules/scripts/s3_to_redshift.py "s3://nexabrands-prod-code/scripts/"

    - name: Deploy Glue Job
      run: |
        aws glue update-job \
          --job-name "topdevs-prod-s3-to-redshift-job" \
          --job-update '{
            "Role": "'"${GLUE_ROLE_ARN}"'",
            "Command": {
              "Name": "glueetl",
              "ScriptLocation": "s3://nexabrands-prod-code/scripts/s3_to_redshift.py",
              "PythonVersion": "3"
            },
            "GlueVersion": "4.0",
            "WorkerType": "G.1X",
            "NumberOfWorkers": 2,
            "Timeout": 2880,
            "MaxRetries": 1,
            "DefaultArguments": {
              "--enable-auto-scaling": "true",
              "--enable-continuous-cloudwatch-log": "true",
              "--enable-metrics": "true",
              "--job-language": "python",
              "--TempDir": "s3://nexabrands-prod-code/temporary/",
              "--enable-spark-ui": "true",
              "--spark-event-logs-path": "s3://nexabrands-prod-code/spark-logs/",
              "--redshift-temp-dir": "s3://nexabrands-prod-code/temp/"
            }
          }'