{"uid":"4b4757e66a1912dae1a509f688f20b0f","children":[{"name":"Test defects","children":[{"name":"pyspark.errors.exceptions.captured.SparkUpgradeException: [INCONSISTENT_BEHAVIOR_CROSS_VERSION.DATETIME_PATTERN_RECOGNITION] You may get a different result due to the upgrading to Spark >= 3.0:\nFail to recognize 'EEEE, MMMM d, yyyy' pattern in the DateTimeFormatter. 1) You can set \"spark.sql.legacy.timeParserPolicy\" to \"LEGACY\" to restore the behavior before Spark 3.0. 2) You can form a valid datetime pattern with the guide from 'https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html'.","children":[{"name":"test_clean_agreed_delivery_date","uid":"569e6dbdd53edb2d","parentUid":"212da4e0a10d799fc462a973bcc24575","status":"broken","time":{"start":1744628968067,"stop":1744628968213,"duration":146},"flaky":false,"newFailed":false,"newPassed":false,"newBroken":false,"retriesCount":3,"retriesStatusChange":false,"parameters":[],"tags":[]},{"name":"test_clean_actual_delivery_date","uid":"791653f587a579ff","parentUid":"212da4e0a10d799fc462a973bcc24575","status":"broken","time":{"start":1744628969563,"stop":1744628969700,"duration":137},"flaky":false,"newFailed":false,"newPassed":false,"newBroken":false,"retriesCount":3,"retriesStatusChange":false,"parameters":[],"tags":[]},{"name":"test_clean_order_lines_data_integration","uid":"6c59d94e2200804e","parentUid":"212da4e0a10d799fc462a973bcc24575","status":"broken","time":{"start":1744628972354,"stop":1744628972662,"duration":308},"flaky":false,"newFailed":false,"newPassed":false,"newBroken":false,"retriesCount":3,"retriesStatusChange":false,"parameters":[],"tags":[]}],"uid":"212da4e0a10d799fc462a973bcc24575"}],"uid":"bdbf199525818fae7a8651db9eafe741"}],"name":"categories"}