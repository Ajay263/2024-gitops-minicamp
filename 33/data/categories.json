{"uid":"4b4757e66a1912dae1a509f688f20b0f","children":[{"name":"Test defects","children":[{"name":"pyspark.errors.exceptions.captured.SparkUpgradeException: [INCONSISTENT_BEHAVIOR_CROSS_VERSION.DATETIME_PATTERN_RECOGNITION] You may get a different result due to the upgrading to Spark >= 3.0:\nFail to recognize 'EEEE, MMMM d, yyyy' pattern in the DateTimeFormatter. 1) You can set \"spark.sql.legacy.timeParserPolicy\" to \"LEGACY\" to restore the behavior before Spark 3.0. 2) You can form a valid datetime pattern with the guide from 'https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html'.","children":[{"name":"test_clean_agreed_delivery_date","uid":"e9c138cdd7f25ac2","parentUid":"212da4e0a10d799fc462a973bcc24575","status":"broken","time":{"start":1744634150772,"stop":1744634150913,"duration":141},"flaky":false,"newFailed":false,"newPassed":false,"newBroken":false,"retriesCount":3,"retriesStatusChange":false,"parameters":[],"tags":[]},{"name":"test_clean_actual_delivery_date","uid":"3641f761c25cfa33","parentUid":"212da4e0a10d799fc462a973bcc24575","status":"broken","time":{"start":1744634152295,"stop":1744634152442,"duration":147},"flaky":false,"newFailed":false,"newPassed":false,"newBroken":false,"retriesCount":3,"retriesStatusChange":false,"parameters":[],"tags":[]},{"name":"test_clean_order_lines_data_integration","uid":"94ad5c1818696172","parentUid":"212da4e0a10d799fc462a973bcc24575","status":"broken","time":{"start":1744634155135,"stop":1744634155449,"duration":314},"flaky":false,"newFailed":false,"newPassed":false,"newBroken":false,"retriesCount":3,"retriesStatusChange":false,"parameters":[],"tags":[]}],"uid":"212da4e0a10d799fc462a973bcc24575"}],"uid":"bdbf199525818fae7a8651db9eafe741"}],"name":"categories"}