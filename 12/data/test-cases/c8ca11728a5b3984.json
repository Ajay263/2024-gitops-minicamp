{"uid":"c8ca11728a5b3984","name":"test_write_transformed_data","fullName":"test_order_fulfillment#test_write_transformed_data","historyId":"28307033fe599f5e0294f39cb96a92e9","time":{"start":1741762491937,"stop":1741762491978,"duration":41},"description":"Test that data is correctly written to S3.","descriptionHtml":"<p>Test that data is correctly written to S3.</p>\n","status":"broken","statusMessage":"py4j.protocol.Py4JJavaError: An error occurred while calling o779.save.\n: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"s3\"\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n\tat org.apache.spark.sql.execution.datasources.DataSource.planForWritingFileFormat(DataSource.scala:454)\n\tat org.apache.spark.sql.execution.datasources.DataSource.planForWriting(DataSource.scala:530)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)","statusTrace":"spark = <pyspark.sql.session.SparkSession object at 0x7fb56b7a2f70>\ns3_bucket = 'test-bucket'\n\n    @mock_aws\n    def test_write_transformed_data(spark, s3_bucket):\n        \"\"\"Test that data is correctly written to S3.\"\"\"\n        # Setup\n        data = [\n            (\"FMR32103503\", 1, 0, 0),\n            (\"FMR34103403\", 1, 1, 0),\n            (\"FMR33103602\", 1, 0, 0),\n        ]\n        schema = StructType(\n            [\n                StructField(\"order_id\", StringType(), True),\n                StructField(\"on_time\", IntegerType(), True),\n                StructField(\"in_full\", IntegerType(), True),\n                StructField(\"otif\", IntegerType(), True),\n            ]\n        )\n        df = spark.createDataFrame(data, schema)\n        s3_output_path = f\"s3://{s3_bucket}/output/\"\n    \n        # Execute\n>       write_transformed_data(df, s3_output_path)\n\ntest_order_fulfillment.py:463: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../scripts/order_fulfillment.py:98: in write_transformed_data\n    df.coalesce(1).write.mode(\"overwrite\").format(\"csv\").option(\"header\", \"true\").save(\n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/pyspark/sql/readwriter.py:1463: in save\n    self._jwrite.save(path)\n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/py4j/java_gateway.py:1322: in __call__\n    return_value = get_return_value(\n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/pyspark/errors/exceptions/captured.py:179: in deco\n    return f(*a, **kw)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nanswer = 'xro780'\ngateway_client = <py4j.clientserver.JavaClient object at 0x7fb56b89dc40>\ntarget_id = 'o779', name = 'save'\n\n    def get_return_value(answer, gateway_client, target_id=None, name=None):\n        \"\"\"Converts an answer received from the Java gateway into a Python object.\n    \n        For example, string representation of integers are converted to Python\n        integer, string representation of objects are converted to JavaObject\n        instances, etc.\n    \n        :param answer: the string returned by the Java gateway\n        :param gateway_client: the gateway client used to communicate with the Java\n            Gateway. Only necessary if the answer is a reference (e.g., object,\n            list, map)\n        :param target_id: the name of the object from which the answer comes from\n            (e.g., *object1* in `object1.hello()`). Optional.\n        :param name: the name of the member from which the answer comes from\n            (e.g., *hello* in `object1.hello()`). Optional.\n        \"\"\"\n        if is_error(answer)[0]:\n            if len(answer) > 1:\n                type = answer[1]\n                value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)\n                if answer[1] == REFERENCE_TYPE:\n>                   raise Py4JJavaError(\n                        \"An error occurred while calling {0}{1}{2}.\\n\".\n                        format(target_id, \".\", name), value)\nE                   py4j.protocol.Py4JJavaError: An error occurred while calling o779.save.\nE                   : org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"s3\"\nE                   \tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\nE                   \tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\nE                   \tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\nE                   \tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\nE                   \tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\nE                   \tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\nE                   \tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\nE                   \tat org.apache.spark.sql.execution.datasources.DataSource.planForWritingFileFormat(DataSource.scala:454)\nE                   \tat org.apache.spark.sql.execution.datasources.DataSource.planForWriting(DataSource.scala:530)\nE                   \tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)\nE                   \tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)\nE                   \tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243)\nE                   \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nE                   \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\nE                   \tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nE                   \tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\nE                   \tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\nE                   \tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\nE                   \tat py4j.Gateway.invoke(Gateway.java:282)\nE                   \tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\nE                   \tat py4j.commands.CallCommand.execute(CallCommand.java:79)\nE                   \tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\nE                   \tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\nE                   \tat java.base/java.lang.Thread.run(Thread.java:840)\n\n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/py4j/protocol.py:326: Py4JJavaError","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[{"name":"spark","time":{"start":1741762480456,"stop":1741762483084,"duration":2628},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"s3_bucket","time":{"start":1741762491834,"stop":1741762491937,"duration":103},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false}],"afterStages":[{"name":"s3_bucket::0","time":{"start":1741762492114,"stop":1741762492115,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false}],"labels":[{"name":"suite","value":"test_order_fulfillment"},{"name":"host","value":"fv-az1691-747"},{"name":"thread","value":"3004-MainThread"},{"name":"framework","value":"pytest"},{"name":"language","value":"cpython3"},{"name":"package","value":"test_order_fulfillment"},{"name":"resultFormat","value":"allure2"}],"parameters":[],"links":[],"hidden":true,"retry":true,"extra":{"categories":[],"tags":[]},"source":"c8ca11728a5b3984.json","parameterValues":[]}